# -*- coding: utf-8 -*-
"""lvadsusr73-Ashutosh- lab1-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QnaF10ze5FEmQw63LZMvUhptn1qdIGi1
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

data= pd.read_csv('/content/winequality-red.csv')
data

data.info()

data.fillna(data.median(), inplace=True)
data.info()

missing_values_check = data.isnull().sum()
missing_values_check

data['quality_label'] = data['quality'].apply(lambda x: 1 if x >= 7 else 0)
data

print(data['quality_label'].value_counts())

Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
IQR

outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)

outlier_count = outliers.sum()
outlier_proportion = outlier_count / len(data)
outlier_count, outlier_proportion

import seaborn as sns
sns.heatmap(data.corr(),annot=True)

import matplotlib.pyplot as plt
categorical_features = ['quality']
for feature in categorical_features:
    plt.figure(figsize=(8, 4))
    sns.countplot(x=feature, hue='quality_label', data=data, palette='pastel')
    plt.xlabel(feature)
    plt.ylabel('Count')
    plt.title(f'{feature} vs. Quality Label')
    plt.show()

sns.pairplot(data)

data.duplicated().sum()

data=data.drop_duplicates()

cop = data.copy()

for column in data.columns[:-2]:
    lower_bound = Q1[column] - 1.5 * IQR[column]
    upper_bound = Q3[column] + 1.5 * IQR[column]
    cop[column] = cop[column].clip(lower=lower_bound, upper=upper_bound)

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split


X = cop.drop(['quality', 'quality_label'], axis=1)
y = cop['quality_label']

smote = SMOTE(random_state=42)
x_balanced, y_balanced = smote.fit_resample(X, y)

x_train, x_test, y_train, y_test = train_test_split(x_balanced, y_balanced, test_size=0.2, random_state=42)

rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)
rf.fit(x_train, y_train)
y_pred_rf = rf.predict(x_test)
print(classification_report(y_test, y_pred_rf, target_names=['Bad', 'Good']))

